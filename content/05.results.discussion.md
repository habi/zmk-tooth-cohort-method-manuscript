## Results and Discussion {.page_break_before}

High resolution datasets of large batches of teeth were acquired in an efficient manner with minimized operator effort due to the batch-scanning abilities of the desktop micro-CT scanner.
The acquired datasets were imaged at a voxel size (10 μm) permitting the analysis of the finest features of interest in the teeth.

The batch-characteristics of the proposed dataset preparation and analysis method makes it easy and efficient to begin processing tooth datasets as scanning of a large batch of teeth is already underway.
Our script facilitates short turnaround time for feedback on single scans in the batch, since samples can be processed by the script as soon as they are reconstructed and while other teeth are still being scanned or waiting to be scanned.
Cropping the datasets with a simple algorithm - as described in subsection [Dataset cropping] above - greatly reduces the size of the datasets on disk.

The proposed method is completely devoid of any manual input, all the datasets present on disk are prepared and analyzed automatically.
This allows for a highly reproducible and completely unbiased analysis.
Previous studies [@doi:10.1016/j.joen.2020.08.012; @doi:10.1016/j.joen.2020.03.001] have analyzed teeth with a precisely defined manual protocol which necessitated several, accurately performed manual steps, increasing the likelihood of operator error being introduced.
This is avoided in the method presented here.

Several teeth contained metal fillings (amalgam) in the crown area, which are difficult to penetrate with the X-ray source available to us.
A simple thresholding lead to artefacts that extended to the border of the original dataset, thus for these datasets, there were no gains in disk space.
Since the cropping part only influences the final size of the dataset on disk and not the extraction of the root canal space from the tooth, it is only of minor concern.
Additionally, the implants or metal fillings in several teeth made it impossible to automatically detect the enamel-dentin border.
If an implant or filling is present in the tooth, the largest derivation in the gray value profile along the tooth is situated at the bottom end of the implant.
The function to extract the EDB was implemented in a way that a manual extraction of the border and the corresponding slices along the tooth axis was possible.

The reformatting of only the bottom part of the tooth greatly facilitated the analysis of the geometry of the physical foramen of each tooth.
While all reconstructions of a single tooth are more than 1 GB in size, these partial datasets are only around 22 MB per tooth.
In total, the bottom 3.5 mm of all 104 teeth occupied only 2.3 GB of disk space, making further assessment of the foramen easily and efficiently possible on a standard office laptop.

The non-destructively acquired three-dimensional datasets of the tooth can also be used for additional analysis of tooth morphology, akin to the process outlined by Di Angelo et al. [@doi:10.1016/j.compbiomed.2016.01.018], Peters et al. [@doi:10.1016/j.joen.2015.06.007] or Paqué et al. [@doi:10.1016/j.joen.2009.04.020].
Further work will focus on automatically extracting a description of the physiological foramen which will allow for dentists to gain important information required for a successful root canal treatment.

The hereby presented workflow is based completely on free and open-source software and – can therefore be verified independently by any interested reader.
The Jupyter notebook described here is also freely available online [@doi:10.5281/zenodo.3999402].
A copy with two samples from the cohort can be run in your browser without installing any software via *Binder* [@doi:10.25080/majora-4af1f417-011] by [clicking a single button](https://mybinder.org/v2/gh/habi/zmk-tooth-cohort/master?filepath=ToothAnalysis.ipynb) in the [README file](https://github.com/habi/zmk-tooth-cohort/blob/master/README.md) of the [project repository](https://github.com/habi/zmk-tooth-cohort/).
